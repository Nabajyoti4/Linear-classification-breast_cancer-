{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Linear classification(breast_cancer).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDFDaoV0G0YrIWr5f1pepi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nabajyoti4/Linear-classification-breast_cancer-/blob/main/Linear_classification(breast_cancer).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXAqt5QUgyU"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSZobdbeV7kT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61690571-0f9a-4612-84fe-7df5c7e9bf8c"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-99wruoV96Q"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2IMf3ylWGyx"
      },
      "source": [
        "data = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdEFmwlfWKzx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "outputId": "6f832b2c-a187-46b0-d38e-588e8eb2e752"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DESCR': '.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.',\n",
              " 'data': array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "         1.189e-01],\n",
              "        [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "         8.902e-02],\n",
              "        [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "         8.758e-02],\n",
              "        ...,\n",
              "        [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "         7.820e-02],\n",
              "        [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "         1.240e-01],\n",
              "        [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "         7.039e-02]]),\n",
              " 'feature_names': array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "        'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "        'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "        'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "        'smoothness error', 'compactness error', 'concavity error',\n",
              "        'concave points error', 'symmetry error',\n",
              "        'fractal dimension error', 'worst radius', 'worst texture',\n",
              "        'worst perimeter', 'worst area', 'worst smoothness',\n",
              "        'worst compactness', 'worst concavity', 'worst concave points',\n",
              "        'worst symmetry', 'worst fractal dimension'], dtype='<U23'),\n",
              " 'filename': '/usr/local/lib/python3.6/dist-packages/sklearn/datasets/data/breast_cancer.csv',\n",
              " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "        0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "        1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "        1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "        0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "        1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "        1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "        1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "        1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]),\n",
              " 'target_names': array(['malignant', 'benign'], dtype='<U9')}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y43Om65tWOKf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8373c346-9861-4a72-9469-5f0139f7f58a"
      },
      "source": [
        "# the data is in the form of dictionary\n",
        "\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv5oHmjvWkXD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "908ddc5d-a0b9-4511-d205-94d6f68fc6de"
      },
      "source": [
        "data.data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuqqurCNWpn_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4cc8802-79f7-4134-bb84-4a2916ed5f1b"
      },
      "source": [
        "data.data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoYmMMhWWtxA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27cd5cfc-3ba0-4a42-c0c9-1b74663af678"
      },
      "source": [
        "data.DESCR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'.. _breast_cancer_dataset:\\n\\nBreast cancer wisconsin (diagnostic) dataset\\n--------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 569\\n\\n    :Number of Attributes: 30 numeric, predictive attributes and the class\\n\\n    :Attribute Information:\\n        - radius (mean of distances from center to points on the perimeter)\\n        - texture (standard deviation of gray-scale values)\\n        - perimeter\\n        - area\\n        - smoothness (local variation in radius lengths)\\n        - compactness (perimeter^2 / area - 1.0)\\n        - concavity (severity of concave portions of the contour)\\n        - concave points (number of concave portions of the contour)\\n        - symmetry \\n        - fractal dimension (\"coastline approximation\" - 1)\\n\\n        The mean, standard error, and \"worst\" or largest (mean of the three\\n        largest values) of these features were computed for each image,\\n        resulting in 30 features.  For instance, field 3 is Mean Radius, field\\n        13 is Radius SE, field 23 is Worst Radius.\\n\\n        - class:\\n                - WDBC-Malignant\\n                - WDBC-Benign\\n\\n    :Summary Statistics:\\n\\n    ===================================== ====== ======\\n                                           Min    Max\\n    ===================================== ====== ======\\n    radius (mean):                        6.981  28.11\\n    texture (mean):                       9.71   39.28\\n    perimeter (mean):                     43.79  188.5\\n    area (mean):                          143.5  2501.0\\n    smoothness (mean):                    0.053  0.163\\n    compactness (mean):                   0.019  0.345\\n    concavity (mean):                     0.0    0.427\\n    concave points (mean):                0.0    0.201\\n    symmetry (mean):                      0.106  0.304\\n    fractal dimension (mean):             0.05   0.097\\n    radius (standard error):              0.112  2.873\\n    texture (standard error):             0.36   4.885\\n    perimeter (standard error):           0.757  21.98\\n    area (standard error):                6.802  542.2\\n    smoothness (standard error):          0.002  0.031\\n    compactness (standard error):         0.002  0.135\\n    concavity (standard error):           0.0    0.396\\n    concave points (standard error):      0.0    0.053\\n    symmetry (standard error):            0.008  0.079\\n    fractal dimension (standard error):   0.001  0.03\\n    radius (worst):                       7.93   36.04\\n    texture (worst):                      12.02  49.54\\n    perimeter (worst):                    50.41  251.2\\n    area (worst):                         185.2  4254.0\\n    smoothness (worst):                   0.071  0.223\\n    compactness (worst):                  0.027  1.058\\n    concavity (worst):                    0.0    1.252\\n    concave points (worst):               0.0    0.291\\n    symmetry (worst):                     0.156  0.664\\n    fractal dimension (worst):            0.055  0.208\\n    ===================================== ====== ======\\n\\n    :Missing Attribute Values: None\\n\\n    :Class Distribution: 212 - Malignant, 357 - Benign\\n\\n    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\\n\\n    :Donor: Nick Street\\n\\n    :Date: November, 1995\\n\\nThis is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\\nhttps://goo.gl/U2Uwz2\\n\\nFeatures are computed from a digitized image of a fine needle\\naspirate (FNA) of a breast mass.  They describe\\ncharacteristics of the cell nuclei present in the image.\\n\\nSeparating plane described above was obtained using\\nMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\\nConstruction Via Linear Programming.\" Proceedings of the 4th\\nMidwest Artificial Intelligence and Cognitive Science Society,\\npp. 97-101, 1992], a classification method which uses linear\\nprogramming to construct a decision tree.  Relevant features\\nwere selected using an exhaustive search in the space of 1-4\\nfeatures and 1-3 separating planes.\\n\\nThe actual linear program used to obtain the separating plane\\nin the 3-dimensional space is that described in:\\n[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\\nProgramming Discrimination of Two Linearly Inseparable Sets\",\\nOptimization Methods and Software 1, 1992, 23-34].\\n\\nThis database is also available through the UW CS ftp server:\\n\\nftp ftp.cs.wisc.edu\\ncd math-prog/cpo-dataset/machine-learn/WDBC/\\n\\n.. topic:: References\\n\\n   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \\n     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \\n     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\\n     San Jose, CA, 1993.\\n   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \\n     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \\n     July-August 1995.\\n   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\\n     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \\n     163-171.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClaXdyARWy2n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "d5032be5-670a-4d6c-ef2b-1e2a073d15f9"
      },
      "source": [
        "data.target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPUP7VYhW4SH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bec20387-01a5-462f-ebc2-73731997e316"
      },
      "source": [
        "data.target.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ikl2-z1W8oI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55f7fb0f-06d5-4cf8-f500-61918b173ca2"
      },
      "source": [
        "data.target_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['malignant', 'benign'], dtype='<U9')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbK_du7XAnH"
      },
      "source": [
        "# malignant means have breast cancer\n",
        "# benign means no cancer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "undu4QPQXW34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "0a3355e1-04a4-4d53-97c8-b286b090789e"
      },
      "source": [
        "data.feature_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
              "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
              "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
              "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
              "       'smoothness error', 'compactness error', 'concavity error',\n",
              "       'concave points error', 'symmetry error',\n",
              "       'fractal dimension error', 'worst radius', 'worst texture',\n",
              "       'worst perimeter', 'worst area', 'worst smoothness',\n",
              "       'worst compactness', 'worst concavity', 'worst concave points',\n",
              "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spJu7-88Xa5n"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(data.data, columns=data.feature_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMEJO4QYXuMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "outputId": "7dfe8fce-59af-4722-9f8e-c21c6bdd92af"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows Ã— 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0          17.99         10.38  ...          0.4601                  0.11890\n",
              "1          20.57         17.77  ...          0.2750                  0.08902\n",
              "2          19.69         21.25  ...          0.3613                  0.08758\n",
              "3          11.42         20.38  ...          0.6638                  0.17300\n",
              "4          20.29         14.34  ...          0.2364                  0.07678\n",
              "..           ...           ...  ...             ...                      ...\n",
              "564        21.56         22.39  ...          0.2060                  0.07115\n",
              "565        20.13         28.25  ...          0.2572                  0.06637\n",
              "566        16.60         28.08  ...          0.2218                  0.07820\n",
              "567        20.60         29.33  ...          0.4087                  0.12400\n",
              "568         7.76         24.54  ...          0.2871                  0.07039\n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIi03c6jX05H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61eb586e-7670-4254-f990-f09abfb6f2e3"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tElXBmvUX8M3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "1c732e2c-b638-4d5b-f682-90b7d19cdfa0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst symmetry  worst fractal dimension\n",
              "0        17.99         10.38  ...          0.4601                  0.11890\n",
              "1        20.57         17.77  ...          0.2750                  0.08902\n",
              "2        19.69         21.25  ...          0.3613                  0.08758\n",
              "3        11.42         20.38  ...          0.6638                  0.17300\n",
              "4        20.29         14.34  ...          0.2364                  0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCQtsKa5X-O_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ciFf2WfIYNKh"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9irzl6ZYB1"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.fit_transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-m5krjCZd4Zb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "8c4576be-8191-4418-b30e-9c3ee3298ffa"
      },
      "source": [
        "X_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.24753743, -0.88050585,  0.22396488, ...,  0.3477625 ,\n",
              "         0.08310832, -0.03918803],\n",
              "       [ 0.60665228,  0.57530889,  0.63921664, ..., -0.16710093,\n",
              "        -0.28492213, -0.26575371],\n",
              "       [-0.05457506, -1.41529494, -0.0710498 , ..., -0.21672632,\n",
              "        -1.25733287, -0.65351893],\n",
              "       ...,\n",
              "       [-0.875409  , -1.03591465, -0.89742146, ..., -0.92916083,\n",
              "        -0.53140124,  0.40175642],\n",
              "       [-0.4763925 ,  1.06896036, -0.33300962, ...,  1.63647186,\n",
              "         2.46686519,  6.82314847],\n",
              "       [-0.66450028, -0.63596554, -0.53877616, ...,  1.10144812,\n",
              "         4.84386922,  1.03436768]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHppuj2Ld7Ke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a6af0413-6893-4b7e-b35a-0d8d8957dae9"
      },
      "source": [
        "# build the model]\n",
        "N, D = X_train.shape\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Input(shape=(D, )),\n",
        "                                    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# train the model\n",
        "r = model.fit(X_train, y_train,\n",
        "              validation_data=(X_test, y_test),\n",
        "              epochs=100)\n",
        "\n",
        "\n",
        "# evaluate model\n",
        "print(\"Train score\", model.evaluate(X_train, y_train))\n",
        "print(\"Test score\", model.evaluate(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "15/15 [==============================] - 0s 13ms/step - loss: 1.0142 - accuracy: 0.4330 - val_loss: 0.8595 - val_accuracy: 0.4825\n",
            "Epoch 2/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.9291 - accuracy: 0.4791 - val_loss: 0.7682 - val_accuracy: 0.5351\n",
            "Epoch 3/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.8396 - accuracy: 0.5165 - val_loss: 0.6875 - val_accuracy: 0.5789\n",
            "Epoch 4/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7934 - accuracy: 0.5648 - val_loss: 0.6195 - val_accuracy: 0.6140\n",
            "Epoch 5/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.6154 - val_loss: 0.5589 - val_accuracy: 0.6667\n",
            "Epoch 6/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6365 - accuracy: 0.6484 - val_loss: 0.5110 - val_accuracy: 0.7018\n",
            "Epoch 7/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6879 - val_loss: 0.4678 - val_accuracy: 0.7456\n",
            "Epoch 8/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7231 - val_loss: 0.4325 - val_accuracy: 0.7982\n",
            "Epoch 9/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7516 - val_loss: 0.4019 - val_accuracy: 0.8333\n",
            "Epoch 10/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7670 - val_loss: 0.3751 - val_accuracy: 0.8509\n",
            "Epoch 11/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.4461 - accuracy: 0.7868 - val_loss: 0.3527 - val_accuracy: 0.8947\n",
            "Epoch 12/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8022 - val_loss: 0.3323 - val_accuracy: 0.9035\n",
            "Epoch 13/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3965 - accuracy: 0.8154 - val_loss: 0.3149 - val_accuracy: 0.9123\n",
            "Epoch 14/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8286 - val_loss: 0.3000 - val_accuracy: 0.9123\n",
            "Epoch 15/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3588 - accuracy: 0.8418 - val_loss: 0.2866 - val_accuracy: 0.9211\n",
            "Epoch 16/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8571 - val_loss: 0.2746 - val_accuracy: 0.9386\n",
            "Epoch 17/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8725 - val_loss: 0.2646 - val_accuracy: 0.9474\n",
            "Epoch 18/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8769 - val_loss: 0.2552 - val_accuracy: 0.9474\n",
            "Epoch 19/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8857 - val_loss: 0.2469 - val_accuracy: 0.9474\n",
            "Epoch 20/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2864 - accuracy: 0.8901 - val_loss: 0.2389 - val_accuracy: 0.9474\n",
            "Epoch 21/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.8923 - val_loss: 0.2314 - val_accuracy: 0.9561\n",
            "Epoch 22/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8967 - val_loss: 0.2250 - val_accuracy: 0.9561\n",
            "Epoch 23/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.9011 - val_loss: 0.2193 - val_accuracy: 0.9649\n",
            "Epoch 24/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2479 - accuracy: 0.9099 - val_loss: 0.2136 - val_accuracy: 0.9649\n",
            "Epoch 25/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.9209 - val_loss: 0.2085 - val_accuracy: 0.9649\n",
            "Epoch 26/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9253 - val_loss: 0.2043 - val_accuracy: 0.9649\n",
            "Epoch 27/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9319 - val_loss: 0.2002 - val_accuracy: 0.9649\n",
            "Epoch 28/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2245 - accuracy: 0.9319 - val_loss: 0.1964 - val_accuracy: 0.9649\n",
            "Epoch 29/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9363 - val_loss: 0.1923 - val_accuracy: 0.9649\n",
            "Epoch 30/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.9385 - val_loss: 0.1886 - val_accuracy: 0.9649\n",
            "Epoch 31/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.2073 - accuracy: 0.9407 - val_loss: 0.1852 - val_accuracy: 0.9649\n",
            "Epoch 32/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9429 - val_loss: 0.1818 - val_accuracy: 0.9649\n",
            "Epoch 33/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9451 - val_loss: 0.1786 - val_accuracy: 0.9649\n",
            "Epoch 34/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1951 - accuracy: 0.9451 - val_loss: 0.1755 - val_accuracy: 0.9649\n",
            "Epoch 35/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1894 - accuracy: 0.9451 - val_loss: 0.1730 - val_accuracy: 0.9649\n",
            "Epoch 36/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1790 - accuracy: 0.9451 - val_loss: 0.1706 - val_accuracy: 0.9649\n",
            "Epoch 37/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1849 - accuracy: 0.9473 - val_loss: 0.1681 - val_accuracy: 0.9649\n",
            "Epoch 38/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 0.9473 - val_loss: 0.1657 - val_accuracy: 0.9649\n",
            "Epoch 39/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9495 - val_loss: 0.1635 - val_accuracy: 0.9649\n",
            "Epoch 40/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1763 - accuracy: 0.9516 - val_loss: 0.1614 - val_accuracy: 0.9649\n",
            "Epoch 41/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1708 - accuracy: 0.9516 - val_loss: 0.1597 - val_accuracy: 0.9649\n",
            "Epoch 42/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1616 - accuracy: 0.9582 - val_loss: 0.1580 - val_accuracy: 0.9649\n",
            "Epoch 43/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1591 - accuracy: 0.9582 - val_loss: 0.1562 - val_accuracy: 0.9649\n",
            "Epoch 44/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1600 - accuracy: 0.9582 - val_loss: 0.1541 - val_accuracy: 0.9649\n",
            "Epoch 45/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9604 - val_loss: 0.1523 - val_accuracy: 0.9649\n",
            "Epoch 46/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1530 - accuracy: 0.9626 - val_loss: 0.1507 - val_accuracy: 0.9649\n",
            "Epoch 47/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1460 - accuracy: 0.9626 - val_loss: 0.1494 - val_accuracy: 0.9649\n",
            "Epoch 48/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.9626 - val_loss: 0.1480 - val_accuracy: 0.9649\n",
            "Epoch 49/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1446 - accuracy: 0.9692 - val_loss: 0.1465 - val_accuracy: 0.9649\n",
            "Epoch 50/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1392 - accuracy: 0.9714 - val_loss: 0.1451 - val_accuracy: 0.9649\n",
            "Epoch 51/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9736 - val_loss: 0.1439 - val_accuracy: 0.9649\n",
            "Epoch 52/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1408 - accuracy: 0.9736 - val_loss: 0.1426 - val_accuracy: 0.9649\n",
            "Epoch 53/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1395 - accuracy: 0.9736 - val_loss: 0.1414 - val_accuracy: 0.9649\n",
            "Epoch 54/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9758 - val_loss: 0.1402 - val_accuracy: 0.9737\n",
            "Epoch 55/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.9758 - val_loss: 0.1392 - val_accuracy: 0.9737\n",
            "Epoch 56/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9758 - val_loss: 0.1383 - val_accuracy: 0.9737\n",
            "Epoch 57/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9758 - val_loss: 0.1373 - val_accuracy: 0.9737\n",
            "Epoch 58/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1306 - accuracy: 0.9780 - val_loss: 0.1364 - val_accuracy: 0.9737\n",
            "Epoch 59/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1265 - accuracy: 0.9780 - val_loss: 0.1353 - val_accuracy: 0.9737\n",
            "Epoch 60/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1247 - accuracy: 0.9780 - val_loss: 0.1344 - val_accuracy: 0.9737\n",
            "Epoch 61/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1191 - accuracy: 0.9780 - val_loss: 0.1336 - val_accuracy: 0.9737\n",
            "Epoch 62/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1209 - accuracy: 0.9780 - val_loss: 0.1328 - val_accuracy: 0.9737\n",
            "Epoch 63/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1210 - accuracy: 0.9802 - val_loss: 0.1321 - val_accuracy: 0.9737\n",
            "Epoch 64/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9802 - val_loss: 0.1315 - val_accuracy: 0.9737\n",
            "Epoch 65/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9802 - val_loss: 0.1307 - val_accuracy: 0.9737\n",
            "Epoch 66/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1227 - accuracy: 0.9802 - val_loss: 0.1299 - val_accuracy: 0.9737\n",
            "Epoch 67/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1194 - accuracy: 0.9802 - val_loss: 0.1296 - val_accuracy: 0.9737\n",
            "Epoch 68/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9802 - val_loss: 0.1289 - val_accuracy: 0.9737\n",
            "Epoch 69/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9802 - val_loss: 0.1283 - val_accuracy: 0.9737\n",
            "Epoch 70/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9802 - val_loss: 0.1279 - val_accuracy: 0.9737\n",
            "Epoch 71/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.9824 - val_loss: 0.1273 - val_accuracy: 0.9737\n",
            "Epoch 72/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1119 - accuracy: 0.9824 - val_loss: 0.1266 - val_accuracy: 0.9737\n",
            "Epoch 73/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1103 - accuracy: 0.9824 - val_loss: 0.1260 - val_accuracy: 0.9737\n",
            "Epoch 74/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9824 - val_loss: 0.1253 - val_accuracy: 0.9737\n",
            "Epoch 75/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.9824 - val_loss: 0.1249 - val_accuracy: 0.9737\n",
            "Epoch 76/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1037 - accuracy: 0.9824 - val_loss: 0.1243 - val_accuracy: 0.9737\n",
            "Epoch 77/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9824 - val_loss: 0.1239 - val_accuracy: 0.9737\n",
            "Epoch 78/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9824 - val_loss: 0.1232 - val_accuracy: 0.9737\n",
            "Epoch 79/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9824 - val_loss: 0.1227 - val_accuracy: 0.9737\n",
            "Epoch 80/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9824 - val_loss: 0.1224 - val_accuracy: 0.9737\n",
            "Epoch 81/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9824 - val_loss: 0.1220 - val_accuracy: 0.9737\n",
            "Epoch 82/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9824 - val_loss: 0.1216 - val_accuracy: 0.9737\n",
            "Epoch 83/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9846 - val_loss: 0.1212 - val_accuracy: 0.9737\n",
            "Epoch 84/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9846 - val_loss: 0.1208 - val_accuracy: 0.9737\n",
            "Epoch 85/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9846 - val_loss: 0.1203 - val_accuracy: 0.9737\n",
            "Epoch 86/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9868 - val_loss: 0.1200 - val_accuracy: 0.9737\n",
            "Epoch 87/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9868 - val_loss: 0.1196 - val_accuracy: 0.9737\n",
            "Epoch 88/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9890 - val_loss: 0.1194 - val_accuracy: 0.9737\n",
            "Epoch 89/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0968 - accuracy: 0.9890 - val_loss: 0.1191 - val_accuracy: 0.9737\n",
            "Epoch 90/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9912 - val_loss: 0.1187 - val_accuracy: 0.9737\n",
            "Epoch 91/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0900 - accuracy: 0.9912 - val_loss: 0.1185 - val_accuracy: 0.9737\n",
            "Epoch 92/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9912 - val_loss: 0.1182 - val_accuracy: 0.9737\n",
            "Epoch 93/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9912 - val_loss: 0.1181 - val_accuracy: 0.9737\n",
            "Epoch 94/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9912 - val_loss: 0.1177 - val_accuracy: 0.9737\n",
            "Epoch 95/100\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9912 - val_loss: 0.1172 - val_accuracy: 0.9737\n",
            "Epoch 96/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0904 - accuracy: 0.9912 - val_loss: 0.1170 - val_accuracy: 0.9737\n",
            "Epoch 97/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0923 - accuracy: 0.9912 - val_loss: 0.1169 - val_accuracy: 0.9737\n",
            "Epoch 98/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9912 - val_loss: 0.1166 - val_accuracy: 0.9737\n",
            "Epoch 99/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9912 - val_loss: 0.1164 - val_accuracy: 0.9737\n",
            "Epoch 100/100\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9912 - val_loss: 0.1162 - val_accuracy: 0.9737\n",
            "15/15 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9912\n",
            "Train score [0.08493734896183014, 0.9912087917327881]\n",
            "4/4 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9737\n",
            "Test score [0.1161520704627037, 0.9736841917037964]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGk2byN1gCH5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "04db300a-9e0a-499a-f73c-dd984c009015"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(r.history['loss'], label='loss')\n",
        "plt.plot(r.history['val_loss'], label='val_loss')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBTdd70ShYnq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b67ae3e3-f518-4c88-a961-26e825559f56"
      },
      "source": [
        "plt.plot(r.history['accuracy'], label='acc')\n",
        "plt.plot(r.history['val_accuracy'], label='val_acc')\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deXxVd53/8dcnOySQhCSsARL2RUhbllKptdNFqUtrWyuty1i3zu83U+3UWWy141LXUR9uv6kL41RLdYoWq0WlrdKiSAVs2ClJaAiEJGS5ZCMhZP/+/jiXNIRAbsJNbu697+fjkcfNPffccz6HU99+8z3f8z3mnENERMJfTKgLEBGR4FCgi4hECAW6iEiEUKCLiEQIBbqISISIC9WOMzMzXU5OTqh2LyISlnbv3n3KOZfV32chC/ScnBzy8/NDtXsRkbBkZqUX+0xdLiIiEUKBLiISIQYMdDN73MxqzOzQRT43M/uemRWb2QEzuyr4ZYqIyEACaaH/FFhzic9vAeb6f+4DfnD5ZYmIyGANGOjOuW1A3SVWuQ1Y7zw7gTQzmxKsAkVEJDDB6EOfBpT1el/uX3YBM7vPzPLNLN/n8wVh1yIics6IXhR1zq1zzi13zi3Pyup3GKWIiAxRMMahVwDTe73P9i8TERlVursdR2qa2FVSR21zW8jquHHhJPKmpwV9u8EI9E3A/Wa2AbgaaHTOVQZhuyIig9bd7SisamJHSS35x+tobusEoMu/vO5MOwBmoatx4vik0AS6mT0FXA9kmlk58DkgHsA590NgM/A2oBhoAT4U9CpFJCp1dHVTWnuGru4LPzvb0UX+8Tp2ltSy50QDbR1dAHR2O9o6vS9MnzCGrJTEnu9cPz+La2ZlcM3sDLLTx47IMYykAQPdOXfPAJ874J+CVpGIjDjnHK/VNLO/rIHO7tA/xazuTDs7S2rZXVpPS3vXJdfNyRjLTQsnMj4pHvBa3gsmj2fV7AympY0ZiXJHjZDN5SIigWlu6+SVY3XsPFZLvb+7IJiaWjt55Xgdp5qDv+3LMW9SCu9els2VM9JIjIu94PPYGGNpdipTUqMrtC9FgS4yRM45mvz9s5fS7A/MnSW17CtrpKO//oOL6O52lNa10NXtiI81Mnt1HwRLQlwMb5rrdUUsy0knOSH0sTAmPpbUsfGhLiPshP7MiYwy50ZCVDW29vt5ZWMrO47Wsv9oObNa9hNDYAE9JiGWt2SmkJR0YWvzUiZNS2TB5PHMnphCYtxwtaIrvZ9L3UIowTNxEaTPDPpmFegS9c71H+8sqWXH0Vp2ltRS39Jxye/MTmnnZ7FfZnrCa4Pb2akhFFgJFA3hezJ6vf1bsOIjQd+sAl2i1pm2Tr72XCHPHarilH9M8rS0MdywYBLXzM4gNzO536FtE+wMMze/F6sphTt+DJlzRrhyCXup0wdeZwgU6OHubAPUHw91FWGntK6Fr24uoKLhLO+Zm8UV01NZMi2NyamJGA6vKd1Pc7q7Czb/C9QUwNqfw7y3jHTpIhelQA9nNYXwxDvgjObFGayZwA8BEoBS/0+gYuJh7c8U5jLqKNDDla8InngnWCy8+ycQlxTqikKq9kw7RVWnKaxqoqiqidoBhvfNn5zCx940i7QxCYPfWcYcyJo3xEpFho8CPVx0tELbae/30xXwv2u93z/424gPF+ccT+eX8/jLx+jq56aXlvYuKhockEHa2Mmsys3gTbMzWJk7gbR+hr7FmDFxXCIWynu/RYaBAj0cVO6HJ2+HltrXlyVnwb2/j/gwb2nv5JHfHOKZPRUszU4lO/3Cm0jiY2P4SHYuq2ZlsGDyOGJiFNQSnRToo13VQVh/GySkwNse9s8oZDD3ZkibEerqgqrmdCs7Smop8Z3pWfbcoUpeq2nmn2+ay8dvmEuswlrkohToo1nVIXjiVohP9rpWJuSGuqKgOtXc1jP2u2+QnzNpfCJPfvhqrp2bGYIKRcKLAj0UXv0NbPoEtDdfej3XBeOmwr2jL8ydc1Q0nOXsABMndTsoqm5ix9FadpXU4mvyxns76JnWNCUxjhU56dy9YjrXzMpk0dTxaomLDIECfaQd3gQbPwxT8mD2DZdeNyYOrrgH0nNGpLRLcc5xoq7lvBZ19enAHxAwLjGOlbkTePP8LAwvrLPGJbJq1gSWTEslLnZEH54lEpEU6COp4Hew8UMwbRl84BlIHBfqii6pvL7Ffyu8N7FURcNZADJTElg1K4OrZ2WQHsAEStPTx7J46niFtsgwU6CPlLK/wdP3wpQr4P2/GpVhXtl4tmcukx0ltZTVeQGePjaeVbMy+Ic3z+KaWRnMmZiiIX8io5ACfaS8+CiMneCFedL4UFdznoPljXxnyxFeLKwBIHVMPFfnTuDDq3O5ZnYG8yZqKKBIOFCgj4TSv8Lxv8BbvwJjgv8cwcF4rbqJ5w9Vce7+nIMVjWwpqCZ1TDwP3jSPmxZNZOHk8QpwkTCkQB8Jf/5P70agZaF93OrT+WX8x7OHaO14ff7u1DHxfPLmeXxodQ7jkvRAAZFwpkAfbid2Qcmf4OYvQkJoHkp7tr2Lzz57iKd3l/PG2Rl8Z+0VPU++MUP94SIRQoE+3P78NRibOSyT2Q+krbOLX7xSxve3HqW6qZVP3DCHB26apzHeIhFKgT6cjv0Fjr4EN30BEpJHdNdbDlfzH88eorKxlRU56XzvnitZmTthRGsQkZGlQB8uFXtgw/u8m4JWfHREd32oopF//N89zM5K4RvvzmP1nAx1q4hEAQX6cDi5D558F4xJhQ/+DhJTRmzXdWfa+Ycnd5OZnMDPPrKSjGF4SryIjE4K9GA4uRcOPA04cA72PwWJ470wTxueZwf2p6vb8Ymn9uJrbmPj/7lGYS4SZRTol+vETnjyDujueP2pQWkz4O6fQ/rMESvDOcdXNxewvfgUX79zKUuzQzveXURGXkCBbmZrgO8CscCPnXNf6/P5TOBxIAuoA97vnCsPcq2jT9nf4Gd3wvgp3sMmxk0OSRnOOb71xyP8ePsx/v6ambxnxcj9VSAio8eAsyWZWSzwGHALsAi4x8wW9Vntm8B659xS4FHgq8EudNQpz/da5imTvK6VEIU5wHdffI3/91Ixa5dP5/PvXByyOkQktAKZ/m4lUOycK3HOtQMbgNv6rLMIeMn/+9Z+Po8s5bu9R8IlZ8K9v/Na6CHQ3NbJVzYX8J0tr/HuZdl89Y4lumVfJIoF0uUyDSjr9b4cuLrPOvuBO/C6ZW4HxplZhnOulkhTsccL87ET/GE+dcRLONPWyfodpazbdpT6lg7uXjGdL9+uMBeJdsG6KPqvwH+Z2b3ANqACuOBRNmZ2H3AfwIwZYfg8zMr9/uGIaV43S2r2iO7+bHsXP9tZyg//fJTaM+28eV4WD948jyum6wKoiAQW6BVA76ts2f5lPZxzJ/Fa6JhZCnCnc66h74acc+uAdQDLly93Q6w5dP7wCMSN8VrmIzQcsbvbUVB1mj8f8fH49uOcam7j2jmZPHjzXJbN1J2fIvK6QAL9FWCumeXiBfndwHt7r2BmmUCdc64beBhvxEtk6e6Gir2w9D3esMRhdqiikR/++Sjbi0/R0NIBwDWzMvj++67SLfwi0q8BA90512lm9wMv4A1bfNw596qZPQrkO+c2AdcDXzUzh9fl8k/DWHNo1B+D9iaYesWw7ubwydN8Z8sR/nC4mvFJcbx18WSumZ3BqlkZTE0bM6z7FpHwFlAfunNuM7C5z7LP9vp9I7AxuKWNMif3eq9Thi/QN+0/yT9v2EtyYhwP3jSPD12bw3jNUS4iAdKdooGq3AexCZC1YFg2//sDlTz4i30sz5nAf39gOakBPHxZRKQ3BXqgKvfDpMUQlxD0TT93sJJPbNjLVTPS+Mm9K0hO1GkRkcFTcgTCOS/QF98R1M1WNJzlv14q5pf5ZVwxPY2ffGilwlxEhkzpEYj6Y9DaCFPygrK51o4uvrK5gKf+dgLDeO/KGfz7mvmkKMxF5DIoQQJRud97DdIIl8e2FrN+Ryn3rJzB/TfMYZpGr4hIECjQA3FyH8TEw8S+c5INYVMNZ1m3rYRb86by1TuWBKE4ERFPIJNzSeU+mLgQ4i7/gRFff74QgE/dMjyjZUQkeinQB3LugmgQulv2lTXwm30n+eibctXNIiJBp0AfSMMJOFt/2TcUOef44u8Ok5mSyP+9fk6QihMReZ0CfSCV+7zXywz03x+sZHdpPf/6lnkazSIiw0KBPpDK/RAT591UNEStHV187blCFkwex13L9Xg4ERkeCvSBlOdD1kKITxryJn761+OU15/lkbcvIlYPoRCRYaJAv5SaAji2Dea9dcibONXcxn+9VMyNCyZy7dzMIBYnInI+BfqlbPsGxI+Fa4Y+G/C3/3iE1o4uPv32hUEsTETkQgr0i/EVwaFnYOXHvOeHDkFRVRNP/e0E7181k9lZKUEuUETkfAr0i9n2TYgfA2/8+JC+3tXteOiZA4wfE88DN84NcnEiIhdSoPfnVDEc2ggrPgrJQ+v3/snLx9h7ooEv3LqY9OTgT7krItKXAr0/f/kmxCYOuXV+7NQZvvFCETctnMiteVODXJyISP8U6H11dcDhZyFvLaRMHPTXu7sdn9p4gIS4GL58+xLMNExRREaGAr2vk3uhowVm/d2Qvv7kzlL+dryO/3jHIiaNH/rYdRGRwVKg93V8u/c6c/Wgv1pW18J/Pl/IdfOyuGtZdpALExG5NAV6X8e3ew+CTska1Necc3zqVweIMeOrd6irRURGngK9t65OKNs1pNb5U38r469Ha3n4bQs0Na6IhIQCvbfK/dDeDDnXDuprJxvO8pXNBbxxdgbvXTljmIoTEbk0BXpvx//ivQ6ihe6c4+FnDtLV7fjaHUvV1SIiIaNA7630ZciYC+MmBfyVX+2p4M9HfHxqzXxmZIwdxuJERC5NgX5OVyec2Dmo7pbq0608+ttXWZGTzt9fkzN8tYmIBCCgQDezNWZWZGbFZvZQP5/PMLOtZrbXzA6Y2duCX+owqzoAbacDDnTnHJ/59SHaOrv5+rvziNE85yISYgMGupnFAo8BtwCLgHvMbFGf1R4BfumcuxK4G/h+sAsddqUve68B9p//9kAlWwqq+de3zCc3M3kYCxMRCUwgLfSVQLFzrsQ51w5sAG7rs44Dxvt/TwVOBq/EEXL8ZZgwG8ZPGXDVlvZOvvz7w+Rlp/Lha3NHoDgRkYEFEujTgLJe78v9y3r7PPB+MysHNgP9zmplZveZWb6Z5ft8viGUO0ycgxM7YOYbA1r9R38uofp0G59952I9Uk5ERo1gXRS9B/ipcy4beBvwpJldsG3n3Drn3HLn3PKsrMHdiTmsmqqgtQEmLx1w1crGs/xo21HesXQKy2amj0BxIiKBCSTQK4Dej6rP9i/r7SPALwGcczuAJCB8HqDpK/Res+YPuOo3ni+i28Gn1iwY5qJERAYnkEB/BZhrZrlmloB30XNTn3VOADcCmNlCvEAfRX0qAzgX6BMv/dzPA+UNPLO3go9cm8v0CRpzLiKjy4CB7pzrBO4HXgAK8EazvGpmj5rZrf7V/gX4mJntB54C7nXOueEqOuh8hTAmHZIv3Q30jReKyEhO4B+vnz1ChYmIBC4ukJWcc5vxLnb2XvbZXr8fBgY/o9Vo4SvyZli8xG37RVVN/OW1U/z7mvmMS4ofweJERAKjO0Wdg5oCL9Av4fHtx0iKj9HkWyIyainQm2u8ES6XCPTa5jZ+va+CO6/KJm2sHvgsIqOTAj2AES4/33WC9s5uPrRaNxGJyOilQPcVea8XaaG3dXbx5M5Srp+fxZyJKSNYmIjI4CjQfYWQlArjJvf78e/2V+JrauPDap2LyCinQPcVXnSES1e340fbjjJ3Ygpvmhs+90mJSHRSoPsKL9p//otXyjhS3cyDN8/Tk4hEZNSL7kA/cwpaavvtP29q7eBbfyxiRU46t7yh/+4YEZHRJLoDvWeEy4WB/v0/HeVUczuPvH2RWuciEhaiO9BrCrzXPoFeVtfC/2w/xu1XTiNveloIChMRGbzoDnRfESSMg/FTz1v8zT8UEWPwb28dePZFEZHRIsoD3X9BtFeXSlNrB5sPVvLelTOZmjYmhMWJiAxOlAd6EUw8v7tl25FTdHQ51uhCqIiEmegN9GYfnKmBrPPnQH+xoJr0sfFcNUN95yISXqI30Cv3ea9Tr+hZ1NnVzUtFNfzdgonExUbvP42IhKfoTa2T/kCfvKRn0e7SehpaOrh54aQQFSUiMnTRG+iV+2DCbG8eF78tBdUkxMbwpnmj6AHWIiIBiuJA339ed4tzjj8ermbV7AxSEgN6kJOIyKgSnYF+phYay2BKXs+io74zHK9t4eaFE0NYmIjI0EVnoJ+7IDrl9Rb6loJqAG5U/7mIhKkoD/TXW+hbDlezaMp43UwkImErOgP95D5Iz4Ex3ljzptYO9pyo54YF6m4RkfAVnYFeuf+87pb80nq6HVwzOyOERYmIXJ7oC/SWOmgoPW+Ey86SWuJjjatmpIewMBGRyxN9gV51wHvt1X++q6SOpdlpjEmIDVFRIiKXL/oC/eT5I1zOtHVysKKRq3MnhLAoEZHLF1Cgm9kaMysys2Ize6ifz79tZvv8P0fMrCH4pQZJ5T5ImwFjvQDfXVpPV7dj1Sz1n4tIeBvwlkgziwUeA24GyoFXzGyTc+7wuXWccw/2Wv/jwJXDUGtwVO4/r7tlZ0ktsTHGspnqPxeR8BZIC30lUOycK3HOtQMbgNsusf49wFPBKC7ozjZAXcl5I1x2HatjybRUknW7v4iEuUACfRpQ1ut9uX/ZBcxsJpALvHSRz+8zs3wzy/f5fIOt9fKd2Om9Tr8agLPtXRwob+DqWeo/F5HwF+yLoncDG51zXf196Jxb55xb7pxbnpUVghkNj/8FYhMgezkAe07U09Gl/nMRiQyBBHoFML3X+2z/sv7czWjtbgEofRmyV0C8d3v/rpJaYgyWq/9cRCJAIIH+CjDXzHLNLAEvtDf1XcnMFgDpwI7glhgkrY3eBdGZq3sW7Syp4w3TUhmXFB/CwkREgmPAQHfOdQL3Ay8ABcAvnXOvmtmjZnZrr1XvBjY459zwlHqZTuwC1w051wLQ1tnFvrIGjT8XkYgR0NAO59xmYHOfZZ/t8/7zwStrGJRuh5h4r8sFePXkadq7ulk2U4EuIpEheu4UPb4dpi2DhLEA7CmtB+DKGWmhrEpEJGiiI9Dbmrxb/v3dLQB7yxqYljaGSeOTQliYiEjwREegl+0C1wU5r18Q3XeiQa1zEYko0RHox7dDTFzPDUXVp1upaDjLlZouV0QiSJQE+ssw9SpISAZg7wlv7jC10EUkkkR+oLefgZN7zutu2VtWT0JsDIunjg9hYSIiwRX5gV51CLo7e7pbwGuhL5o6nsQ4PdBCRCJH5Ae6r9B7nbgQgM6ubg6U64KoiESe6Aj0+LGQOgOAwqomWju69fxQEYk40RHomfMgxjvUvSd0Q5GIRKYoCPQiyFrQ83bviQayxiUyLW1MCIsSEQm+yA701tNwugKy5vcs2lvWwJXT0zCzEBYmIhJ8kR3oviLv1X9BtLa5jWOnzuiGIhGJSBEe6P4RLv4W+o6SWgBW6ZFzIhKBIj/Q45IgbSYALxefYlxiHEumpYa4MBGR4IvwQC+CzLkQ491A9HJxLatmZxAXG9mHLSLRKbKTzVfYM8KlrK6FE3UtrJ6tB0KLSGSK3EBva4LGsp5Af7n4FADXzs0MZVUiIsMmcgP91BHv1R/o24tPMXFcIrOzUkJYlIjI8IncQD83ZDFrAd3djh1Ha1k9J1Pjz0UkYkVwoBdCbAKk51BU3UTtmXZWz1F3i4hErsgN9Br/HC6xcT3956vn6IKoiESuyA10X2HPDUUvF59iVlYyU1I1f4uIRK7IDPT2M9BwArIW0N7Zza5jdayere4WEYlskRnoviLAQdZ8CqtO09LexapZ6m4RkcgWmYFetst7nXoVRVVNACycMi6EBYmIDL/IDPTj2735W9Kmc6S6iYS4GGZmJIe6KhGRYRVQoJvZGjMrMrNiM3voIuu8x8wOm9mrZva/wS1zELq7ofSvkHMtAEXVzcydmEJsjMafi0hkixtoBTOLBR4DbgbKgVfMbJNz7nCvdeYCDwOrnXP1ZjZxuAoekK8Aztb1BPqRqibeqPlbRCQKBNJCXwkUO+dKnHPtwAbgtj7rfAx4zDlXD+CcqwlumYNw/GXvdeZqGls6qDrdyrzJ6j8XkcgXSKBPA8p6vS/3L+ttHjDPzF42s51mtqa/DZnZfWaWb2b5Pp9vaBUPpHQ7pE6H9JkcqfEuiM6fpEAXkcgXrIuiccBc4HrgHuC/zSyt70rOuXXOueXOueVZWVlB2vV5O/Ba6Of6z/0jXNRCF5FoEEigVwDTe73P9i/rrRzY5JzrcM4dA47gBfzI8hVByymYuRqAI9VNpCTGMTU1acRLEREZaYEE+ivAXDPLNbME4G5gU591foPXOsfMMvG6YEqCWGdgSrd7rzleoBdVNTFvUopmWBSRqDBgoDvnOoH7gReAAuCXzrlXzexRM7vVv9oLQK2ZHQa2Av/mnKsdrqIv6vh2GDcV0nNxznGkuon56m4RkSgx4LBFAOfcZmBzn2Wf7fW7Az7p/wmNc/3ns64HM3xNrdS3dDBPF0RFJEpEzp2itcVwpqanu+VIVTOgES4iEj0iJ9DPzd8y440AFFVrhIuIRJfICfST+yAhBTLmAN4dohnJCWSmJIa4MBGRkRE5gV65HyYvhRjvkIqqm9R/LiJRJTICvasTqg7C1CsAcM7xmka4iEiUiYxAP3UEOs/CFC/QKxrOcqa9Sy10EYkqkRHolfu81yl5wOu3/M+fnBKqikRERlyEBPp+iE+GTG+2gcJzc7iohS4iUSQyAv3kPpi8BGJiASioPM30CWMYlxQf4sJEREZO+Ad6dxdUHejpbgGvhb5g8vgQFiUiMvLCP9Bri6GjpWeES2tHFyW+ZhZqhIuIRJnwD/ST5y6IeoFeXNNMt4MFU9RCF5HoEv6BXrkP4sZA5jzA6z8HWKAWuohEmfAP9JP7YPIbINabOLKwqomk+BhmZiSHuDARkZEV3oHe3e2/IHpFz6LCqtPMnzSO2Bg91EJEokt4B3rdUWhvPu+W/4JKjXARkegU3oFeud979Q9Z9DW3UXemnQVT1H8uItEnvAO95jBYLGTOB6Cw0rtDVC10EYlG4R3oviLImA1xCYDXfw4a4SIi0SnMA70Qshb0vC2sbGLy+CTSkxNCWJSISGiEb6B3tkFdyXmBXlDVpP5zEYla4Rvop14D1w1ZXv95R1c3xTUa4SIi0St8A91X6L36W+glvjN0dDkWqoUuIlEqjAO9CCymZw70gxWNACzUHC4iEqXiQl3AkPkKYcIsiEsEYHdpHeOS4piTpacUiYSDjo4OysvLaW1tDXUpo1JSUhLZ2dnExwf+XIfwDvReF0Tzj9ezbGY6MbrlXyQslJeXM27cOHJycjDT/257c85RW1tLeXk5ubm5AX8voC4XM1tjZkVmVmxmD/Xz+b1m5jOzff6fjw6i9sHrbIfaoz0XRBta2nmtppkVOROGdbciEjytra1kZGQozPthZmRkZAz6r5cBW+hmFgs8BtwMlAOvmNkm59zhPqv+wjl3/6D2PlR1R8F1QdZCAHaX1gOwbGb6iOxeRIJDYX5xQ/m3CaSFvhIods6VOOfagQ3AbYPeUzD1jHDxWuivHK8nPtbIy04LYVEiIqEVSKBPA8p6vS/3L+vrTjM7YGYbzWx6fxsys/vMLN/M8n0+3xDK9aspBKxnhMvu0joWT01lTELs0LcpIhLmgjVs8bdAjnNuKfBH4In+VnLOrXPOLXfOLc/Kyhr63nyFkJ4D8WNo6+xif3kjK3LU3SIi0S2QUS4VQO8Wd7Z/WQ/nXG2vtz8Gvn75pV2Crwgmev3nhyoaae/sZtlMXRAVCVdf+O2rHD55OqjbXDR1PJ975+IB13vXu95FWVkZra2tPPDAA9x33308//zzfPrTn6arq4vMzExefPFFmpub+fjHP05+fj5mxuc+9znuvPPOoNZ8uQIJ9FeAuWaWixfkdwPv7b2CmU1xzlX6394KFAS1yt66OqC2GOav8Yo77l0QXa4WuogMweOPP86ECRM4e/YsK1as4LbbbuNjH/sY27ZtIzc3l7q6OgC++MUvkpqaysGDBwGor68PZdn9GjDQnXOdZnY/8AIQCzzunHvVzB4F8p1zm4BPmNmtQCdQB9w7bBXXlUB3R88Y9Pzj9eRmJpOZkjhsuxSR4RVIS3q4fO973+PXv/41AGVlZaxbt47rrruuZ/z3hAneX/9btmxhw4YNPd9LTx99jciAbixyzm0GNvdZ9tlevz8MPBzc0i6i1wgX5xy7S+u4aeGkEdm1iESWP/3pT2zZsoUdO3YwduxYrr/+eq644goKCwtDXdqQhN9cLr4ivBEu8znqO0N9S4e6W0RkSBobG0lPT2fs2LEUFhayc+dOWltb2bZtG8eOHQPo6XK5+eabeeyxx3q+Oxq7XMIv0N/4cfjHHZAwlj09NxTpgqiIDN6aNWvo7Oxk4cKFPPTQQ6xatYqsrCzWrVvHHXfcQV5eHmvXrgXgkUceob6+nje84Q3k5eWxdevWEFd/ofCbyyV+TM8Il1dPNpKcEMuszOQQFyUi4SgxMZHnnnuu389uueWW896npKTwxBP9jsgeNcKvhd7L4crTLJwyXhNyiYgQxoHe3e0oqGxi0VTNfy4iAmEc6GX1LTS3dbJID7QQEQHCONDP3VWmFrqIiCd8A73yNLExxrxJeoaoiAiEc6CfPM2crBSS4jXDoogIhHGgv3rytLpbRER6CctAr21uo+p0qy6IisiISUkZ/Q+gD78bi4CCyiZAF0RFIsZzD0HVweBuc/ISuOVrwd3mKBeWLfTDlY0ALFQLXUSG6KGHHjpvbpbPf/7zfOlLX+LGG2/kqquuYsmSJTz77LMBbau5ufmi31u/fj1Lly4lLy+PD3zgAwBUV1dz++23k5eXR15eHn/961+Dc1DOuZD8LFu2zA3VA0/tcau+slsbFv4AAAaYSURBVGXI3xeR0Dt8+HBI979nzx533XXX9bxfuHChO3HihGtsbHTOOefz+dzs2bNdd3e3c8655OTki26ro6Oj3+8dOnTIzZ071/l8Puecc7W1tc45597znve4b3/728455zo7O11DQ0O/2+3v3whv2vJ+czUsu1wOV55msbpbROQyXHnlldTU1HDy5El8Ph/p6elMnjyZBx98kG3bthETE0NFRQXV1dVMnjz5kttyzvHpT3/6gu+99NJL3HXXXWRmZgKvz63+0ksvsX79egBiY2NJTU0NyjGFXaC3dnRx1HeGNYsv/Q8sIjKQu+66i40bN1JVVcXatWv5+c9/js/nY/fu3cTHx5OTk0Nra+uA2xnq94It7PrQi6qa6Op2uiAqIpdt7dq1bNiwgY0bN3LXXXfR2NjIxIkTiY+PZ+vWrZSWlga0nYt974YbbuDpp5+mttZ77PK5udVvvPFGfvCDHwDQ1dVFY2NjUI4n7AL9cKX/lv8pwfkTRUSi1+LFi2lqamLatGlMmTKF973vfeTn57NkyRLWr1/PggULAtrOxb63ePFiPvOZz/DmN7+ZvLw8PvnJTwLw3e9+l61bt7JkyRKWLVvG4cOHg3I85vWxj7zly5e7/Pz8QX/vD69W8fTucn70/mWaNlckjBUUFLBw4cJQlzGq9fdvZGa7nXPL+1s/7PrQ37J4Mm9R/7mIyAXCLtBFRELl4MGDPWPJz0lMTGTXrl0hquh8CnQRCRnnHGbh03W6ZMkS9u3bNyL7Gkp3eNhdFBWRyJCUlERtbe2QgivSOeeora0lKSlpUN9TC11EQiI7O5vy8nJ8Pl+oSxmVkpKSyM7OHtR3FOgiEhLx8fHk5uaGuoyIoi4XEZEIoUAXEYkQCnQRkQgRsjtFzcwHBDZRwoUygVNBLCdcRONxR+MxQ3QedzQeMwz+uGc657L6+yBkgX45zCz/Yre+RrJoPO5oPGaIzuOOxmOG4B63ulxERCKEAl1EJEKEa6CvC3UBIRKNxx2NxwzRedzReMwQxOMOyz50ERG5ULi20EVEpA8FuohIhAi7QDezNWZWZGbFZvZQqOsZDmY23cy2mtlhM3vVzB7wL59gZn80s9f8r+mhrjXYzCzWzPaa2e/873PNbJf/fP/CzBJCXWOwmVmamW00s0IzKzCza6LkXD/o/+/7kJk9ZWZJkXa+zexxM6sxs0O9lvV7bs3zPf+xHzCzqwa7v7AKdDOLBR4DbgEWAfeY2aLQVjUsOoF/cc4tAlYB/+Q/zoeAF51zc4EX/e8jzQNAQa/3/wl82zk3B6gHPhKSqobXd4HnnXMLgDy844/oc21m04BPAMudc28AYoG7ibzz/VNgTZ9lFzu3twBz/T/3AT8Y7M7CKtCBlUCxc67EOdcObABuC3FNQeecq3TO7fH/3oT3P/BpeMf6hH+1J4B3habC4WFm2cDbgR/73xtwA7DRv0okHnMqcB3wPwDOuXbnXAMRfq794oAxZhYHjAUqibDz7ZzbBtT1WXyxc3sbsN55dgJpZjZlMPsLt0CfBpT1el/uXxaxzCwHuBLYBUxyzlX6P6oCJoWorOHyHeDfgW7/+wygwTnX6X8fiec7F/ABP/F3Nf3YzJKJ8HPtnKsAvgmcwAvyRmA3kX++4eLn9rLzLdwCPaqYWQrwK+CfnXOne3/mvPGmETPm1MzeAdQ453aHupYRFgdcBfzAOXclcIY+3SuRdq4B/P3Gt+H9H9pUIJkLuyYiXrDPbbgFegUwvdf7bP+yiGNm8Xhh/nPn3DP+xdXn/gTzv9aEqr5hsBq41cyO43Wl3YDXt5zm/5McIvN8lwPlzrlzTxneiBfwkXyuAW4CjjnnfM65DuAZvP8GIv18w8XP7WXnW7gF+ivAXP+V8AS8iyibQlxT0Pn7jv8HKHDOfavXR5uAD/p//yDw7EjXNlyccw8757Kdczl45/Ul59z7gK3Au/2rRdQxAzjnqoAyM5vvX3QjcJgIPtd+J4BVZjbW/9/7ueOO6PPtd7Fzuwn4e/9ol1VAY6+umcA458LqB3gbcAQ4Cnwm1PUM0zFei/dn2AFgn//nbXh9yi8CrwFbgAmhrnWYjv964Hf+32cBfwOKgaeBxFDXNwzHewWQ7z/fvwHSo+FcA18ACoFDwJNAYqSdb+ApvGsEHXh/jX3kYucWMLxRfEeBg3gjgAa1P936LyISIcKty0VERC5CgS4iEiEU6CIiEUKBLiISIRToIiIRQoEuIhIhFOgiIhHi/wPNGnIiEs+ujgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVBoE4K7h6zY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}